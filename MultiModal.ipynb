{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import requests\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "# Text processing libraries\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Image processing libraries\n",
        "from skimage import feature, color, measure, filters, segmentation\n",
        "from scipy.stats import skew, kurtosis\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "    nltk.data.find('vader_lexicon')\n",
        "except LookupError:\n",
        "    print(\"Downloading NLTK data...\")\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('vader_lexicon')\n",
        "\n",
        "class ImageSentimentAnalyzer:\n",
        "    \"\"\"Comprehensive image sentiment analyzer using computer vision technique \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize deep learning model for feature extraction\n",
        "        try:\n",
        "            self.image_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "            self.deep_learning_available = True\n",
        "        except:\n",
        "            print(\"Warning: MobileNetV2 not available, using basic image analysis only\")\n",
        "            self.deep_learning_available = False\n",
        "\n",
        "        # Color emotion mapping based on color psychology research\n",
        "        self.color_emotions = {\n",
        "            'red': {'arousal': 0.8, 'valence': 0.2, 'dominance': 0.7},      # High arousal, negative valence\n",
        "            'orange': {'arousal': 0.7, 'valence': 0.6, 'dominance': 0.6},   # Energetic, positive\n",
        "            'yellow': {'arousal': 0.6, 'valence': 0.8, 'dominance': 0.5},   # Happy, bright\n",
        "            'green': {'arousal': 0.3, 'valence': 0.6, 'dominance': 0.4},    # Calm, natural\n",
        "            'blue': {'arousal': 0.2, 'valence': 0.4, 'dominance': 0.3},     # Calm, sometimes sad\n",
        "            'purple': {'arousal': 0.4, 'valence': 0.5, 'dominance': 0.6},   # Mysterious, creative\n",
        "            'pink': {'arousal': 0.5, 'valence': 0.7, 'dominance': 0.3},     # Gentle, loving\n",
        "            'brown': {'arousal': 0.3, 'valence': 0.4, 'dominance': 0.4},    # Natural, stable\n",
        "            'black': {'arousal': 0.4, 'valence': 0.1, 'dominance': 0.8},    # Strong, sometimes negative\n",
        "            'white': {'arousal': 0.2, 'valence': 0.6, 'dominance': 0.3},    # Pure, clean\n",
        "            'gray': {'arousal': 0.1, 'valence': 0.3, 'dominance': 0.2}      # Neutral, sometimes sad\n",
        "        }\n",
        "\n",
        "        # Facial expression patterns (simplified)\n",
        "        self.expression_patterns = {\n",
        "            'smile_curve': 'positive',\n",
        "            'frown_curve': 'negative',\n",
        "            'bright_eyes': 'positive',\n",
        "            'dark_shadows': 'negative'\n",
        "        }\n",
        "\n",
        "    def load_image(self, image_input):\n",
        "        \"\"\"\n",
        "        Load image from various input types (file path, URL, PIL Image)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if isinstance(image_input, str):\n",
        "                if image_input.startswith(('http://', 'https://')):\n",
        "                    # You can load from URL\n",
        "                    response = requests.get(image_input, timeout=10)\n",
        "                    response.raise_for_status()\n",
        "                    img = Image.open(BytesIO(response.content))\n",
        "                else:\n",
        "                    # Load from file path\n",
        "                    if not os.path.exists(image_input):\n",
        "                        raise FileNotFoundError(f\"Image file not found: {image_input}\")\n",
        "                    img = Image.open(image_input)\n",
        "            elif isinstance(image_input, Image.Image):\n",
        "                img = image_input\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported image input type\")\n",
        "\n",
        "            # Convert to RGB if necessary\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "\n",
        "            return img\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image: {e}\")\n",
        "            return None\n",
        "\n",
        "    def analyze_color_sentiment(self, img):\n",
        "        \"\"\"\n",
        "        Analyze sentiment based on color composition and psychology\n",
        "        \"\"\"\n",
        "        img_array = np.array(img)\n",
        "        height, width = img_array.shape[:2]\n",
        "\n",
        "        # Convert to different color spaces\n",
        "        hsv_img = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)\n",
        "        lab_img = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
        "\n",
        "        # Extract color features\n",
        "        features = {}\n",
        "\n",
        "        # 1. Dominant colors analysis\n",
        "        pixels = img_array.reshape(-1, 3)\n",
        "\n",
        "        # Calculate color dominance\n",
        "        r_mean, g_mean, b_mean = np.mean(pixels, axis=0)\n",
        "        r_std, g_std, b_std = np.std(pixels, axis=0)\n",
        "\n",
        "        features['red_dominance'] = r_mean / 255.0\n",
        "        features['green_dominance'] = g_mean / 255.0\n",
        "        features['blue_dominance'] = b_mean / 255.0\n",
        "        features['color_variance'] = np.mean([r_std, g_std, b_std]) / 255.0\n",
        "\n",
        "        # 2. HSV analysis\n",
        "        hue = hsv_img[:, :, 0]\n",
        "        saturation = hsv_img[:, :, 1]\n",
        "        value = hsv_img[:, :, 2]\n",
        "\n",
        "        features['average_hue'] = np.mean(hue)\n",
        "        features['average_saturation'] = np.mean(saturation) / 255.0\n",
        "        features['average_brightness'] = np.mean(value) / 255.0\n",
        "        features['saturation_variance'] = np.std(saturation) / 255.0\n",
        "\n",
        "        # 3. Color temperature (warm vs cool)\n",
        "        warm_pixels = np.sum((pixels[:, 0] > pixels[:, 2]) & (pixels[:, 1] > pixels[:, 2]))\n",
        "        cool_pixels = np.sum((pixels[:, 2] > pixels[:, 0]) & (pixels[:, 2] > pixels[:, 1]))\n",
        "        total_pixels = len(pixels)\n",
        "\n",
        "        features['warmth_ratio'] = warm_pixels / total_pixels\n",
        "        features['coolness_ratio'] = cool_pixels / total_pixels\n",
        "\n",
        "        # 4. Color harmony analysis\n",
        "        hue_std = np.std(hue)\n",
        "        features['color_harmony'] = 1.0 / (1.0 + hue_std / 180.0)  # Higher = more harmonious\n",
        "\n",
        "        # 5. Map to emotional dimensions\n",
        "        sentiment_score = 0\n",
        "        confidence_factors = []\n",
        "\n",
        "        # Brightness sentiment\n",
        "        if features['average_brightness'] > 0.7:\n",
        "            sentiment_score += 0.3  # Bright = positive\n",
        "            confidence_factors.append(0.6)\n",
        "        elif features['average_brightness'] < 0.3:\n",
        "            sentiment_score -= 0.2  # Dark = negative\n",
        "            confidence_factors.append(0.5)\n",
        "\n",
        "        # Saturation sentiment\n",
        "        if features['average_saturation'] > 0.6:\n",
        "            sentiment_score += 0.2  # Vibrant = positive\n",
        "            confidence_factors.append(0.4)\n",
        "        elif features['average_saturation'] < 0.3:\n",
        "            sentiment_score -= 0.1  # Dull = less positive\n",
        "\n",
        "        # Warmth sentiment\n",
        "        if features['warmth_ratio'] > 0.6:\n",
        "            sentiment_score += 0.2  # Warm = positive\n",
        "            confidence_factors.append(0.3)\n",
        "        elif features['coolness_ratio'] > 0.6:\n",
        "            sentiment_score -= 0.1  # Cool = less positive\n",
        "\n",
        "        # Color harmony sentiment\n",
        "        if features['color_harmony'] > 0.7:\n",
        "            sentiment_score += 0.1  # Harmonious = positive\n",
        "\n",
        "        return {\n",
        "            'color_features': features,\n",
        "            'sentiment_score': sentiment_score,\n",
        "            'confidence': min(0.8, np.mean(confidence_factors) if confidence_factors else 0.3)\n",
        "        }\n",
        "\n",
        "    def analyze_texture_sentiment(self, img):\n",
        "        \"\"\"\n",
        "        Analyze sentiment based on texture and patterns\n",
        "        \"\"\"\n",
        "        img_array = np.array(img)\n",
        "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        features = {}\n",
        "\n",
        "        # 1. Edge density analysis\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        edge_density = np.sum(edges > 0) / (gray.shape[0] * gray.shape[1])\n",
        "        features['edge_density'] = edge_density\n",
        "\n",
        "        # 2. Texture smoothness\n",
        "        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        features['texture_roughness'] = laplacian_var / 10000.0  # Normalize\n",
        "\n",
        "        # 3. Local Binary Pattern analysis\n",
        "        try:\n",
        "            from skimage import feature as sk_feature\n",
        "            lbp = sk_feature.local_binary_pattern(gray, P=8, R=1, method='uniform')\n",
        "            lbp_hist, _ = np.histogram(lbp.ravel(), bins=10, range=(0, 9))\n",
        "            lbp_hist = lbp_hist.astype(float)\n",
        "            lbp_hist /= (lbp_hist.sum() + 1e-7)\n",
        "\n",
        "            # Texture uniformity\n",
        "            features['texture_uniformity'] = -np.sum(lbp_hist * np.log2(lbp_hist + 1e-7))\n",
        "        except:\n",
        "            features['texture_uniformity'] = 0.5  # Default value\n",
        "\n",
        "        # 4. Gradient analysis\n",
        "        grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "        features['gradient_strength'] = np.mean(gradient_magnitude) / 255.0\n",
        "\n",
        "        # 5. Contrast analysis\n",
        "        features['contrast'] = np.std(gray) / 255.0\n",
        "\n",
        "        # Sentiment mapping\n",
        "        sentiment_score = 0\n",
        "        confidence_factors = []\n",
        "\n",
        "        # Smooth textures often more pleasant\n",
        "        if features['texture_roughness'] < 0.3:\n",
        "            sentiment_score += 0.1\n",
        "            confidence_factors.append(0.3)\n",
        "        elif features['texture_roughness'] > 0.7:\n",
        "            sentiment_score -= 0.1\n",
        "            confidence_factors.append(0.3)\n",
        "\n",
        "        # Moderate contrast is pleasant\n",
        "        if 0.3 <= features['contrast'] <= 0.7:\n",
        "            sentiment_score += 0.1\n",
        "            confidence_factors.append(0.4)\n",
        "\n",
        "        # High edge density might indicate chaos (negative)\n",
        "        if features['edge_density'] > 0.3:\n",
        "            sentiment_score -= 0.1\n",
        "            confidence_factors.append(0.2)\n",
        "\n",
        "        return {\n",
        "            'texture_features': features,\n",
        "            'sentiment_score': sentiment_score,\n",
        "            'confidence': min(0.6, np.mean(confidence_factors) if confidence_factors else 0.2)\n",
        "        }\n",
        "\n",
        "    def analyze_composition_sentiment(self, img):\n",
        "        \"\"\"\n",
        "        Analyze sentiment based on image composition and layout\n",
        "        \"\"\"\n",
        "        img_array = np.array(img)\n",
        "        height, width = img_array.shape[:2]\n",
        "\n",
        "        features = {}\n",
        "\n",
        "        # 1. Rule of thirds analysis\n",
        "        third_h, third_w = height // 3, width // 3\n",
        "\n",
        "        # Calculate interest points at rule of thirds intersections\n",
        "        interest_points = [\n",
        "            (third_w, third_h), (2 * third_w, third_h),\n",
        "            (third_w, 2 * third_h), (2 * third_w, 2 * third_h)\n",
        "        ]\n",
        "\n",
        "        # 2. Center vs edge brightness\n",
        "        center_region = img_array[height//4:3*height//4, width//4:3*width//4]\n",
        "        edge_regions = np.concatenate([\n",
        "            img_array[:height//4, :].flatten(),  # Top\n",
        "            img_array[3*height//4:, :].flatten(),  # Bottom\n",
        "            img_array[:, :width//4].flatten(),   # Left\n",
        "            img_array[:, 3*width//4:].flatten()  # Right\n",
        "        ])\n",
        "\n",
        "        center_brightness = np.mean(center_region)\n",
        "        edge_brightness = np.mean(edge_regions)\n",
        "        features['center_focus'] = center_brightness / (edge_brightness + 1)\n",
        "\n",
        "        # 3. Symmetry analysis\n",
        "        left_half = img_array[:, :width//2]\n",
        "        right_half = np.fliplr(img_array[:, width//2:])\n",
        "\n",
        "        # Resize to match if needed\n",
        "        min_width = min(left_half.shape[1], right_half.shape[1])\n",
        "        left_half = left_half[:, :min_width]\n",
        "        right_half = right_half[:, :min_width]\n",
        "\n",
        "        symmetry_score = np.mean(np.abs(left_half.astype(float) - right_half.astype(float)))\n",
        "        features['horizontal_symmetry'] = 1.0 / (1.0 + symmetry_score / 255.0)\n",
        "\n",
        "        # 4. Golden ratio analysis (approximation)\n",
        "        golden_ratio = 1.618\n",
        "        golden_y = int(height / golden_ratio)\n",
        "        golden_x = int(width / golden_ratio)\n",
        "\n",
        "        # Check if interesting features align with golden ratio\n",
        "        features['golden_ratio_alignment'] = 0.5  # Simplified for demo\n",
        "\n",
        "        # Sentiment mapping\n",
        "        sentiment_score = 0\n",
        "        confidence_factors = []\n",
        "\n",
        "        # Good composition often positive\n",
        "        if features['center_focus'] > 1.2:  # Center brighter than edges\n",
        "            sentiment_score += 0.15\n",
        "            confidence_factors.append(0.4)\n",
        "\n",
        "        if features['horizontal_symmetry'] > 0.7:  # Good symmetry\n",
        "            sentiment_score += 0.1\n",
        "            confidence_factors.append(0.3)\n",
        "\n",
        "        return {\n",
        "            'composition_features': features,\n",
        "            'sentiment_score': sentiment_score,\n",
        "            'confidence': min(0.5, np.mean(confidence_factors) if confidence_factors else 0.2)\n",
        "        }\n",
        "\n",
        "    def analyze_deep_features(self, img):\n",
        "        \"\"\"\n",
        "        Extract deep learning features if available\n",
        "        \"\"\"\n",
        "        if not self.deep_learning_available:\n",
        "            return {\n",
        "                'deep_features': {},\n",
        "                'sentiment_score': 0,\n",
        "                'confidence': 0\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            # Preprocess image for MobileNetV2\n",
        "            img_resized = img.resize((224, 224))\n",
        "            img_array = np.array(img_resized)\n",
        "            img_expanded = np.expand_dims(img_array, axis=0)\n",
        "            img_preprocessed = preprocess_input(img_expanded)\n",
        "\n",
        "            # Extract features\n",
        "            deep_features = self.image_model.predict(img_preprocessed, verbose=0)\n",
        "\n",
        "            features = {\n",
        "                'deep_feature_mean': np.mean(deep_features),\n",
        "                'deep_feature_std': np.std(deep_features),\n",
        "                'deep_feature_max': np.max(deep_features),\n",
        "                'deep_feature_min': np.min(deep_features),\n",
        "                'deep_feature_energy': np.sum(deep_features ** 2)\n",
        "            }\n",
        "\n",
        "            # Simple sentiment mapping based on feature statistics\n",
        "            sentiment_score = 0\n",
        "            if features['deep_feature_mean'] > 0:\n",
        "                sentiment_score += 0.1\n",
        "            if features['deep_feature_energy'] > np.median(deep_features):\n",
        "                sentiment_score += 0.05\n",
        "\n",
        "            return {\n",
        "                'deep_features': features,\n",
        "                'sentiment_score': sentiment_score,\n",
        "                'confidence': 0.3\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in deep feature extraction: {e}\")\n",
        "            return {\n",
        "                'deep_features': {},\n",
        "                'sentiment_score': 0,\n",
        "                'confidence': 0\n",
        "            }\n",
        "\n",
        "    def analyze_image_sentiment(self, image_input):\n",
        "        \"\"\"\n",
        "        Comprehensive image sentiment analysis\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        img = self.load_image(image_input)\n",
        "        if img is None:\n",
        "            return {\n",
        "                'sentiment': 'Neutral',\n",
        "                'confidence': 0.0,\n",
        "                'error': 'Failed to load image'\n",
        "            }\n",
        "\n",
        "        print(f\"Analyzing image: {img.size}\")\n",
        "\n",
        "        # Perform different types of analysis\n",
        "        color_analysis = self.analyze_color_sentiment(img)\n",
        "        texture_analysis = self.analyze_texture_sentiment(img)\n",
        "        composition_analysis = self.analyze_composition_sentiment(img)\n",
        "        deep_analysis = self.analyze_deep_features(img)\n",
        "\n",
        "        # Combine all sentiment scores\n",
        "        total_score = (\n",
        "            color_analysis['sentiment_score'] * 0.4 +\n",
        "            texture_analysis['sentiment_score'] * 0.3 +\n",
        "            composition_analysis['sentiment_score'] * 0.2 +\n",
        "            deep_analysis['sentiment_score'] * 0.1\n",
        "        )\n",
        "\n",
        "        # Combine confidences\n",
        "        total_confidence = (\n",
        "            color_analysis['confidence'] * 0.4 +\n",
        "            texture_analysis['confidence'] * 0.3 +\n",
        "            composition_analysis['confidence'] * 0.2 +\n",
        "            deep_analysis['confidence'] * 0.1\n",
        "        )\n",
        "\n",
        "        # Determine final sentiment\n",
        "        if total_score > 0.15:\n",
        "            sentiment = 'Positive'\n",
        "            confidence = min(0.9, 0.6 + total_confidence)\n",
        "        elif total_score < -0.15:\n",
        "            sentiment = 'Negative'\n",
        "            confidence = min(0.9, 0.6 + total_confidence)\n",
        "        else:\n",
        "            sentiment = 'Neutral'\n",
        "            confidence = max(0.3, total_confidence)\n",
        "\n",
        "        return {\n",
        "            'sentiment': sentiment,\n",
        "            'confidence': confidence,\n",
        "            'total_score': total_score,\n",
        "            'analysis_breakdown': {\n",
        "                'color_analysis': color_analysis,\n",
        "                'texture_analysis': texture_analysis,\n",
        "                'composition_analysis': composition_analysis,\n",
        "                'deep_analysis': deep_analysis\n",
        "            },\n",
        "            'image_properties': {\n",
        "                'size': img.size,\n",
        "                'mode': img.mode\n",
        "            }\n",
        "        }\n",
        "\n",
        "class MultimodalSentimentAnalyzer:\n",
        "    \"\"\"\n",
        "    Multimodal sentiment analyzer combining text and image analysis\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize text sentiment analyzers\n",
        "        self.vader_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "        # Initialize image analyzer\n",
        "        self.image_analyzer = ImageSentimentAnalyzer()\n",
        "\n",
        "    def analyze_text_sentiment(self, text):\n",
        "        \"\"\"\n",
        "        Analyze text sentiment using multiple approaches\n",
        "        \"\"\"\n",
        "        if not text or text.strip() == \"\":\n",
        "            return {\n",
        "                'sentiment': 'Neutral',\n",
        "                'confidence': 0.0,\n",
        "                'scores': {'positive': 0, 'negative': 0, 'neutral': 1}\n",
        "            }\n",
        "\n",
        "        # Method 1: TextBlob sentiment analysis\n",
        "        blob = TextBlob(text)\n",
        "        textblob_polarity = blob.sentiment.polarity\n",
        "        textblob_subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "        # Method 2: VADER sentiment analysis\n",
        "        vader_scores = self.vader_analyzer.polarity_scores(text)\n",
        "\n",
        "        # Combine both methods\n",
        "        combined_positive = (textblob_polarity > 0.1) or (vader_scores['pos'] > 0.3)\n",
        "        combined_negative = (textblob_polarity < -0.1) or (vader_scores['neg'] > 0.3)\n",
        "\n",
        "        # Determine final sentiment\n",
        "        if combined_positive and not combined_negative:\n",
        "            sentiment = 'Positive'\n",
        "            confidence = min(0.95, abs(textblob_polarity) * 0.5 + vader_scores['pos'])\n",
        "        elif combined_negative and not combined_positive:\n",
        "            sentiment = 'Negative'\n",
        "            confidence = min(0.95, abs(textblob_polarity) * 0.5 + vader_scores['neg'])\n",
        "        else:\n",
        "            sentiment = 'Neutral'\n",
        "            confidence = max(vader_scores['neu'], 0.5)\n",
        "\n",
        "        return {\n",
        "            'sentiment': sentiment,\n",
        "            'confidence': confidence,\n",
        "            'scores': {\n",
        "                'positive': vader_scores['pos'],\n",
        "                'negative': vader_scores['neg'],\n",
        "                'neutral': vader_scores['neu']\n",
        "            },\n",
        "            'textblob_polarity': textblob_polarity,\n",
        "            'textblob_subjectivity': textblob_subjectivity\n",
        "        }\n",
        "\n",
        "    def analyze_multimodal_sentiment(self, text=None, image_path=None, text_weight=0.6, image_weight=0.4):\n",
        "        \"\"\"\n",
        "        Combine text and image sentiment analysis\n",
        "        \"\"\"\n",
        "        results = {\n",
        "            'combined_sentiment': 'Neutral',\n",
        "            'confidence': 0.0,\n",
        "            'modalities_used': []\n",
        "        }\n",
        "\n",
        "        text_result = None\n",
        "        image_result = None\n",
        "\n",
        "        # Analyze text if provided\n",
        "        if text:\n",
        "            text_result = self.analyze_text_sentiment(text)\n",
        "            results['text_analysis'] = text_result\n",
        "            results['modalities_used'].append('text')\n",
        "\n",
        "        # Analyze image if provided\n",
        "        if image_path:\n",
        "            image_result = self.image_analyzer.analyze_image_sentiment(image_path)\n",
        "            results['image_analysis'] = image_result\n",
        "            results['modalities_used'].append('image')\n",
        "\n",
        "        # Combine results if both modalities are present\n",
        "        if text_result and image_result:\n",
        "            # Weighted combination\n",
        "            text_score = self._sentiment_to_score(text_result['sentiment'])\n",
        "            image_score = self._sentiment_to_score(image_result['sentiment'])\n",
        "\n",
        "            combined_score = (text_score * text_weight + image_score * image_weight)\n",
        "            combined_confidence = (text_result['confidence'] * text_weight +\n",
        "                                 image_result['confidence'] * image_weight)\n",
        "\n",
        "            results['combined_sentiment'] = self._score_to_sentiment(combined_score)\n",
        "            results['confidence'] = combined_confidence\n",
        "            results['combined_score'] = combined_score\n",
        "\n",
        "        elif text_result:\n",
        "            results['combined_sentiment'] = text_result['sentiment']\n",
        "            results['confidence'] = text_result['confidence']\n",
        "\n",
        "        elif image_result:\n",
        "            results['combined_sentiment'] = image_result['sentiment']\n",
        "            results['confidence'] = image_result['confidence']\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _sentiment_to_score(self, sentiment):\n",
        "        \"\"\"Convert sentiment to numerical score\"\"\"\n",
        "        mapping = {'Negative': -1, 'Neutral': 0, 'Positive': 1}\n",
        "        return mapping.get(sentiment, 0)\n",
        "\n",
        "    def _score_to_sentiment(self, score):\n",
        "        \"\"\"Convert numerical score to sentiment\"\"\"\n",
        "        if score > 0.2:\n",
        "            return 'Positive'\n",
        "        elif score < -0.2:\n",
        "            return 'Negative'\n",
        "        else:\n",
        "            return 'Neutral'\n",
        "\n",
        "def create_sample_images():\n",
        "    \"\"\"\n",
        "    Create sample images for testing\n",
        "    \"\"\"\n",
        "    sample_images = []\n",
        "\n",
        "    # Create a bright, colorful image (should be positive)\n",
        "    img1 = Image.new('RGB', (300, 200), color=(255, 220, 100))  # Bright yellow\n",
        "    draw1 = ImageDraw.Draw(img1)\n",
        "    draw1.ellipse([50, 50, 150, 150], fill=(255, 100, 100))  # Red circle\n",
        "    draw1.ellipse([150, 25, 250, 125], fill=(100, 255, 100))  # Green circle\n",
        "    sample_images.append(('bright_colors.png', img1, 'Positive'))\n",
        "\n",
        "    # Create a dark, low contrast image (should be negative)\n",
        "    img2 = Image.new('RGB', (300, 200), color=(40, 40, 50))  # Dark blue-gray\n",
        "    draw2 = ImageDraw.Draw(img2)\n",
        "    draw2.rectangle([50, 50, 250, 150], fill=(30, 30, 40))  # Darker rectangle\n",
        "    sample_images.append(('dark_image.png', img2, 'Negative'))\n",
        "\n",
        "    # Create a balanced, neutral image\n",
        "    img3 = Image.new('RGB', (300, 200), color=(128, 128, 128))  # Gray\n",
        "    draw3 = ImageDraw.Draw(img3)\n",
        "    draw3.ellipse([100, 50, 200, 150], fill=(150, 150, 150))  # Light gray circle\n",
        "    sample_images.append(('neutral_image.png', img3, 'Neutral'))\n",
        "\n",
        "    # Save sample images\n",
        "    for filename, img, expected in sample_images:\n",
        "        img.save(filename)\n",
        "        print(f\"Created sample image: {filename} (expected: {expected})\")\n",
        "\n",
        "    return [filename for filename, _, _ in sample_images]\n",
        "\n",
        "def demo_comprehensive_image_analysis():\n",
        "    \"\"\"\n",
        "    Comprehensive demo of image sentiment analysis\n",
        "    \"\"\"\n",
        "    print(\"Comprehensive Image Sentiment Analysis Demo\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    # Create sample images\n",
        "    print(\"\\nCreating sample images for testing...\")\n",
        "    sample_images = create_sample_images()\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = ImageSentimentAnalyzer()\n",
        "\n",
        "    print(f\"\\nAnalyzing {len(sample_images)} sample images:\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    for i, image_path in enumerate(sample_images, 1):\n",
        "        print(f\"\\nImage {i}: {image_path}\")\n",
        "\n",
        "        # Analyze image\n",
        "        result = analyzer.analyze_image_sentiment(image_path)\n",
        "\n",
        "        print(f\"Sentiment: {result['sentiment']}\")\n",
        "        print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "        print(f\"Score: {result['total_score']:.3f}\")\n",
        "\n",
        "        # Show breakdown\n",
        "        breakdown = result['analysis_breakdown']\n",
        "        print(\"Analysis breakdown:\")\n",
        "        print(f\"  Color sentiment: {breakdown['color_analysis']['sentiment_score']:.3f}\")\n",
        "        print(f\"  Texture sentiment: {breakdown['texture_analysis']['sentiment_score']:.3f}\")\n",
        "        print(f\"  Composition sentiment: {breakdown['composition_analysis']['sentiment_score']:.3f}\")\n",
        "\n",
        "        # Show key features\n",
        "        color_features = breakdown['color_analysis']['color_features']\n",
        "        print(f\"  Brightness: {color_features['average_brightness']:.3f}\")\n",
        "        print(f\"  Saturation: {color_features['average_saturation']:.3f}\")\n",
        "        print(f\"  Warmth ratio: {color_features['warmth_ratio']:.3f}\")\n",
        "\n",
        "def demo_multimodal_with_images():\n",
        "    \"\"\"\n",
        "    Demo multimodal analysis with actual images\n",
        "    \"\"\"\n",
        "    print(\"\\nMultimodal Analysis with Images Demo\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    # Create sample images if they don't exist\n",
        "    if not os.path.exists('bright_colors.png'):\n",
        "        create_sample_images()\n",
        "\n",
        "    # Initialize multimodal analyzer\n",
        "    analyzer = MultimodalSentimentAnalyzer()\n",
        "\n",
        "    # Test cases with text and image combinations\n",
        "    test_cases = [\n",
        "        {\n",
        "            'text': \"What a beautiful sunny day!\",\n",
        "            'image': 'bright_colors.png',\n",
        "            'description': \"Positive text + bright image\"\n",
        "        },\n",
        "        {\n",
        "            'text': \"I'm feeling really sad today...\",\n",
        "            'image': 'dark_image.png',\n",
        "            'description': \"Negative text + dark image\"\n",
        "        },\n",
        "        {\n",
        "            'text': \"The weather is okay, nothing special.\",\n",
        "            'image': 'neutral_image.png',\n",
        "            'description': \"Neutral text + neutral image\"\n",
        "        },\n",
        "        {\n",
        "            'text': \"This is amazing!\",\n",
        "            'image': 'dark_image.png',\n",
        "            'description': \"Positive text + dark image (conflict)\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    print(f\"\\nTesting {len(test_cases)} multimodal scenarios:\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        print(f\"\\nTest {i}: {case['description']}\")\n",
        "        print(f\"Text: '{case['text']}'\")\n",
        "        print(f\"Image: {case['image']}\")\n",
        "\n",
        "        # Analyze with different weight combinations\n",
        "        result = analyzer.analyze_multimodal_sentiment(\n",
        "            text=case['text'],\n",
        "            image_path=case['image'],\n",
        "            text_weight=0.6,\n",
        "            image_weight=0.4\n",
        "        )\n",
        "\n",
        "        print(f\"Combined Sentiment: {result['combined_sentiment']}\")\n",
        "        print(f\"Combined Confidence: {result['confidence']:.3f}\")\n",
        "\n",
        "        if 'text_analysis' in result:\n",
        "            print(f\"  Text sentiment: {result['text_analysis']['sentiment']} ({result['text_analysis']['confidence']:.3f})\")\n",
        "\n",
        "        if 'image_analysis' in result:\n",
        "            print(f\"  Image sentiment: {result['image_analysis']['sentiment']} ({result['image_analysis']['confidence']:.3f})\")\n",
        "\n",
        "def analyze_custom_image():\n",
        "    \"\"\"\n",
        "    Allow user to analyze their own image\n",
        "    \"\"\"\n",
        "    print(\"\\nCustom Image Analysis\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    image_path = input(\"Enter image path or URL (or press Enter to skip): \").strip()\n",
        "\n",
        "    if not image_path:\n",
        "        print(\"Skipping custom image analysis\")\n",
        "        return\n",
        "\n",
        "    text_input = input(\"Enter optional text description (or press Enter to skip): \").strip()\n",
        "\n",
        "    # Initialize analyzer\n",
        "    analyzer = MultimodalSentimentAnalyzer()\n",
        "\n",
        "    print(f\"\\nAnalyzing: {image_path}\")\n",
        "    if text_input:\n",
        "        print(f\"With text: '{text_input}'\")\n",
        "\n",
        "    try:\n",
        "        if text_input:\n",
        "            # Multimodal analysis\n",
        "            result = analyzer.analyze_multimodal_sentiment(\n",
        "                text=text_input,\n",
        "                image_path=image_path\n",
        "            )\n",
        "            print(f\"\\nCombined Result:\")\n",
        "            print(f\"Sentiment: {result['combined_sentiment']}\")\n",
        "            print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "\n",
        "            if 'image_analysis' in result:\n",
        "                img_result = result['image_analysis']\n",
        "                print(f\"\\nImage Analysis Details:\")\n",
        "                print(f\"  Sentiment: {img_result['sentiment']}\")\n",
        "\n",
        "        else:\n",
        "            # Image-only analysis\n",
        "            img_result = analyzer.image_analyzer.analyze_image_sentiment(image_path)\n",
        "            print(f\"\\nImage Analysis Result:\")\n",
        "            print(f\"Sentiment: {img_result['sentiment']}\")\n",
        "            print(f\"Confidence: {img_result['confidence']:.3f}\")\n",
        "\n",
        "            if 'analysis_breakdown' in img_result:\n",
        "                print(\"  Analysis Breakdown:\")\n",
        "                for key, value in img_result['analysis_breakdown'].items():\n",
        "                    print(f\"    {key}: Sentiment Score {value['sentiment_score']:.3f}, Confidence {value['confidence']:.3f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError during analysis: {e}\")\n",
        "\n",
        "\n",
        "def create_sample_data():\n",
        "    \"\"\"\n",
        "    Create sample data for testing\n",
        "    \"\"\"\n",
        "    sample_texts = [\n",
        "        \"I absolutely love this movie! It's fantastic and amazing!\",\n",
        "        \"This product is terrible and I regret buying it.\",\n",
        "        \"The service was okay, nothing special but not bad either.\",\n",
        "        \"Incredible performance! Outstanding work by everyone involved!\",\n",
        "        \"Worst experience ever. Completely disappointed and frustrated.\"\n",
        "    ]\n",
        "\n",
        "    return sample_texts\n",
        "\n",
        "def demo_multimodal_analysis():\n",
        "    \"\"\"\n",
        "    Demonstrate the multimodal sentiment analyzer (text only for simplicity in this version)\n",
        "    \"\"\"\n",
        "    print(\"Multimodal Sentiment Analysis Demo (Text Only)\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    # Create analyzer\n",
        "    analyzer = MultimodalSentimentAnalyzer()\n",
        "\n",
        "    # Test cases\n",
        "    test_cases = create_sample_data()\n",
        "\n",
        "    print(\"\\nText Sentiment Analysis:\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    for i, text in enumerate(test_cases, 1):\n",
        "        result = analyzer.analyze_text_sentiment(text)\n",
        "        print(f\"\\nTest {i}:\")\n",
        "        print(f\"Text: '{text}'\")\n",
        "        print(f\"Sentiment: {result['sentiment']}\")\n",
        "        print(f\"Confidence: {result['confidence']:.3f}\")\n",
        "        if 'scores' in result:\n",
        "            print(f\"  Scores: Pos {result['scores']['positive']:.3f}, Neg {result['scores']['negative']:.3f}, Neu {result['scores']['neutral']:.3f}\")\n",
        "\n",
        "    # Example of combined analysis (conceptually, would need image input)\n",
        "    print(\"\\nConceptual Multimodal Example:\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "    print(\"Analyzing text 'Great picture!' and a hypothetical positive image...\")\n",
        "    conceptual_result = analyzer.analyze_multimodal_sentiment(text=\"Great picture!\", text_weight=0.7, image_weight=0.3)\n",
        "    print(f\"  Combined Sentiment (conceptual): Positive\") # Assuming positive image analysis\n",
        "    print(f\"  Combined Confidence (conceptual): High\") # Assuming high confidence\n",
        "\n",
        "\n",
        "def batch_sentiment_analysis():\n",
        "    \"\"\"\n",
        "    Perform batch sentiment analysis on sample data\n",
        "    \"\"\"\n",
        "    print(\"Batch Sentiment Analysis\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    # Create analyzer\n",
        "    analyzer = MultimodalSentimentAnalyzer()\n",
        "\n",
        "    # Get sample data\n",
        "    texts = create_sample_data()\n",
        "\n",
        "    results = []\n",
        "    for i, text in enumerate(texts, 1):\n",
        "        result = analyzer.analyze_text_sentiment(text)\n",
        "\n",
        "        results.append({\n",
        "            'id': i,\n",
        "            'text': text[:50] + \"...\" if len(text) > 50 else text,\n",
        "            'sentiment': result['sentiment'],\n",
        "            'confidence': result['confidence']\n",
        "        })\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\nAnalyzed {len(texts)} texts:\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    for result in results:\n",
        "        print(f\"{result['id']}. {result['text']}\")\n",
        "        print(f\"   Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.3f})\")\n",
        "        print()\n",
        "\n",
        "    # Summary statistics\n",
        "    sentiments = [r['sentiment'] for r in results]\n",
        "    positive_count = sentiments.count('Positive')\n",
        "    negative_count = sentiments.count('Negative')\n",
        "    neutral_count = sentiments.count('Neutral')\n",
        "\n",
        "    print(\"Summary:\")\n",
        "    print(f\"Positive: {positive_count}, Negative: {negative_count}, Neutral: {neutral_count}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Multimodal Sentiment Analysis with Alternative Libraries\")\n",
        "    print(\"-------------------------------------------------------------------------\")\n",
        "\n",
        "    choice = input(\"\\nChoose demo:\\n1. Basic demo (Text Only)\\n2. Batch analysis\\n3. Comprehensive Image Analysis Demo\\n4. Multimodal Analysis with Images Demo\\n5. Analyze Custom Image\\nEnter choice (1, 2, 3, 4, or 5): \")\n",
        "\n",
        "    if choice == \"2\":\n",
        "        batch_sentiment_analysis()\n",
        "    elif choice == \"3\":\n",
        "        demo_comprehensive_image_analysis()\n",
        "    elif choice == \"4\":\n",
        "        demo_multimodal_with_images()\n",
        "    elif choice == \"5\":\n",
        "        analyze_custom_image()\n",
        "    else:\n",
        "        demo_multimodal_analysis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXpTwPjwA5OF",
        "outputId": "94b4b310-babf-439c-fe7a-293bfb9029bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading NLTK data...\n",
            "Multimodal Sentiment Analysis with Alternative Libraries\n",
            "-------------------------------------------------------------------------\n",
            "\n",
            "Choose demo:\n",
            "1. Basic demo (Text Only)\n",
            "2. Batch analysis\n",
            "3. Comprehensive Image Analysis Demo\n",
            "4. Multimodal Analysis with Images Demo\n",
            "5. Analyze Custom Image\n",
            "Enter choice (1, 2, 3, 4, or 5): 4\n",
            "\n",
            "Multimodal Analysis with Images Demo\n",
            "-------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-945518230.py:50: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  self.image_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing 4 multimodal scenarios:\n",
            "-------------------------------------------------------------------------\n",
            "\n",
            "Test 1: Positive text + bright image\n",
            "Text: 'What a beautiful sunny day!'\n",
            "Image: bright_colors.png\n",
            "Analyzing image: (300, 200)\n",
            "Combined Sentiment: Positive\n",
            "Combined Confidence: 0.930\n",
            "  Text sentiment: Positive (0.950)\n",
            "  Image sentiment: Positive (0.900)\n",
            "\n",
            "Test 2: Negative text + dark image\n",
            "Text: 'I'm feeling really sad today...'\n",
            "Image: dark_image.png\n",
            "Analyzing image: (300, 200)\n",
            "Combined Sentiment: Negative\n",
            "Combined Confidence: 0.560\n",
            "  Text sentiment: Negative (0.680)\n",
            "  Image sentiment: Neutral (0.380)\n",
            "\n",
            "Test 3: Neutral text + neutral image\n",
            "Text: 'The weather is okay, nothing special.'\n",
            "Image: neutral_image.png\n",
            "Analyzing image: (300, 200)\n",
            "Combined Sentiment: Positive\n",
            "Combined Confidence: 0.388\n",
            "  Text sentiment: Positive (0.447)\n",
            "  Image sentiment: Neutral (0.300)\n",
            "\n",
            "Test 4: Positive text + dark image (conflict)\n",
            "Text: 'This is amazing!'\n",
            "Image: dark_image.png\n",
            "Analyzing image: (300, 200)\n",
            "Combined Sentiment: Positive\n",
            "Combined Confidence: 0.722\n",
            "  Text sentiment: Positive (0.950)\n",
            "  Image sentiment: Neutral (0.380)\n"
          ]
        }
      ]
    }
  ]
}